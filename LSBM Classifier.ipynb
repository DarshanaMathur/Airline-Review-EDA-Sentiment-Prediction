{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About the Data\n\n![](https://cdn.britannica.com/41/123141-050-E6229449/Air-New-Zealand-Boeing-747-400.jpg)\n\nThe data used here comes from a 2-part preprocessing of the original data.\n\nThe original data was preprocessed in 2 different stages, the preprocessing notebooks could be found here:\n\n   * [Part 1](https://www.kaggle.com/divyansh22/airline-reviews-eda-and-preprocessing-pt-1)\n   \n   * [Part 2](https://www.kaggle.com/divyansh22/airline-review-data-preprocessing-pt-2-nlp)\n   \nThe original data could be found [here](https://www.kaggle.com/efehandanisman/skytrax-airline-reviews).","metadata":{}},{"cell_type":"markdown","source":"# 1. Decide the model configuration","metadata":{}},{"cell_type":"code","source":"use_review_text = True  # Change it to False, if you don't want review text included for training\nuse_count_vectorization = True  # Change it to False to exclude count_vectorization","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not use_review_text:\n    # Without review text.\n    df_types_filename = '../input/airline-reviews-eda-and-preprocessing-pt-1/PreprocessedDataLightTypes.csv'\n    df_filename = '../input/airline-reviews-eda-and-preprocessing-pt-1/PreprocessedDataLight.csv'\n    df_out_filename = './Preds-WithoutText.csv'\nelse:\n    # With review text.\n    df_types_filename = '../input/airline-review-data-preprocessing-pt-2-nlp/NLPFinalDataLightTypes.csv'\n    df_filename = '../input/airline-review-data-preprocessing-pt-2-nlp/NLPFinalDataLight.csv'\n    df_out_filename = './Preds-WithText.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define numerical and categorical features.\nif not use_review_text:\n    # Without review text.\n    num_feats = ['date_flown_month',\n                 'date_flown_year',\n                 'review_date_date_flown_distance_days',\n                 'review_characters',\n                 'has_layover_num',\n                 'seat_comfort',\n                 'cabin_service',\n                 'food_bev',\n                 'entertainment',\n                 'ground_service',\n                 'value_for_money']\n    cat_feats = ['airline',\n                 'traveller_type',\n                 'cabin']\nelse:\n    # With review text.\n    if not use_count_vectorization:\n        num_feats = ['date_flown_month',\n                     'date_flown_year',\n                     'review_date_date_flown_distance_days',\n                     'review_characters',\n                     'has_layover_num',\n                     'seat_comfort',\n                     'cabin_service',\n                     'food_bev',\n                     'entertainment',\n                     'ground_service',\n                     'value_for_money',\n                     'polarity']\n    else:\n        with open('../input/airline-review-data-preprocessing-pt-2-nlp/VecReviewTextCleanFeats.csv','r') as f:\n            vec_feats = f.read()\n            vec_feats = vec_feats.split(', ')\n        num_feats = ['date_flown_month',\n                     'date_flown_year',\n                     'review_date_date_flown_distance_days',\n                     'review_characters',\n                     'has_layover_num',\n                     'seat_comfort',\n                     'cabin_service',\n                     'food_bev',\n                     'entertainment',\n                     'ground_service',\n                     'value_for_money',\n                     'polarity'] + vec_feats\n    cat_feats = ['airline',\n                 'traveller_type',\n                 'cabin']\n\nfeats = num_feats + cat_feats","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set this variable to the desired method for data transformation.\n# Possible options are: scaling_and_one_hot_encoding, label_encoding, no_transformation.\ntransform_dataset = 'label_encoding'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Necessary Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_palette('Set2')\nimport scipy.sparse\n\nimport datetime as dt\nimport dateutil\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.metrics import roc_curve, accuracy_score, roc_auc_score, confusion_matrix \n\nimport lightgbm as lgb\n\nimport importlib","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Load the input data","metadata":{}},{"cell_type":"code","source":"# Type of each field in the input data.\ndf_dtype = pd.read_csv(df_types_filename)\ndict_dtype = df_dtype[['index','dtypes']].set_index('index').to_dict()['dtypes']\ndict_dtype['recommended'] = 'bool'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input data.\ndf = pd.read_csv(df_filename, dtype=dict_dtype, keep_default_na=False, na_values=['_'])\ndf.drop(columns=['Unnamed: 0'],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_reviews = df.shape[0]\nprint('Number of customer reviews in the dataset: {:d}'.format(n_reviews))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Model training and prediction for the recommendation of airline by customers","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Label the data on the basis of 'recommended' column","metadata":{}},{"cell_type":"code","source":"# Utility function to assign the label to our dataset\ndef assign_label_recommended(df_row):\n    \"\"\"\n    Return 0 if not recommended and 1 otherwise.\n    \"\"\"\n    label_recommended = None\n    if df_row['recommended'] == True:\n        label_recommended = 1\n    elif df_row['recommended'] == False:\n        label_recommended = 0\n    else:\n        label_recommended = None\n    return label_recommended","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'] = df.apply(lambda x: assign_label_recommended(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Convert Boolean features to numerical","metadata":{}},{"cell_type":"code","source":"df['has_layover_num'] = df['has_layover'].astype(int)\ndf['date_flown_day'] = df['date_flown_day'].astype(int)\ndf['date_flown_month'] = df['date_flown_month'].astype(int)\ndf['date_flown_year'] = df['date_flown_year'].astype(int)\n\ndf['seat_comfort'] = df['seat_comfort'].astype(int)\ndf['cabin_service'] = df['cabin_service'].astype(int)\ndf['ground_service'] = df['ground_service'].astype(int)\ndf['food_bev'] = df['food_bev'].astype(int)\ndf['value_for_money'] = df['value_for_money'].astype(int)\ndf['entertainment'] = df['entertainment'].astype(int)\n\nfor feat in num_feats:\n    if 'polarity' not in feat:\n        df[feat] = df[feat].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Select features for training and labels for prediction","metadata":{}},{"cell_type":"code","source":"X = df[feats]\ny = df['label'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.4 Check for class imbalance","metadata":{}},{"cell_type":"code","source":"f_rec = (y[y==1].shape[0])/y.shape[0]\nf_not_rec = (y[y==0].shape[0])/y.shape[0]\nprint('Fraction of customers that recommeded the service: {:.2f}'.format(f_rec))\nprint('Fraction of customers that did not recommed the service: {:.2f}'.format(f_not_rec))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.5 Scaling numerical features and encoding the categorical features\nWe might want to scale numerical features, so that they have values in a common range.\n\nHere, we use the StandardScaler available in the sklearn library to normalize the features, that is, to subtract their mean and divide by their standard deviation. We transform x to z = (x-u)/s. We can specify whether or no we want to subtract the mean with the option with_mean=True/False and whether or not we want to divide by the standard deviation with the option with_std=True/False. As a result, all the numerical features will have mean zero and unit standard deviation.\n\nWe also need to transform categorical features as well. Two common options are one-hot encoding and label encoding.\n\n1.  **One-hot encoding** allows to encode categorical features as one-hot vectors. The categorical feature is transformed into binary features, one for each category.\n\n    For example, the categorical feature 'cabin' can have four possible values: Economy Class, Premium Economy, Business Class and First Class. The one-hot encoding transform this feature, with four possible values, into four new features, called cabin_Economy, cabin_Premium Economy, cabin_Business and cabin_First, with each new feature having two possible values, 0 or 1, depending on the value of the original feature. A record with cabin equal to Economy Class will have cabin_Economy Class equal to 1 and all the other three features equal to 0.\n    This could lead to sparse data (most of the elements in the dataset will have the value 0) if the features can have many possible values.\n\n2. **Label encoding** allows to encode categorical features as numbers.\n\n    For example, the categorical feature cabin can be encoded as one feature with values 0, 1, 2 and 3.\n\nHere, we use a pipeline to define the data processing, so that we can repeat the same steps for the training and test datasets. In particular, the parameters of the data processing are defined based on the training dataset and are then applied to the test dataset.","metadata":{}},{"cell_type":"code","source":"# Create a pipeline for numerical features and a pipeline for categorical features.\nnum_proc = make_pipeline(SimpleImputer(missing_values=np.nan, strategy='mean'), StandardScaler())\ncat_proc = make_pipeline(SimpleImputer(strategy='constant', fill_value='missing'), OneHotEncoder(handle_unknown='ignore'))\n\n# Create a preprocessing step for all features.\npreprocessor = make_column_transformer((num_proc, num_feats),\n                                       (cat_proc, cat_feats))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.6 Dataset for training and testing","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.6.1 Transform the data before training using the pipeline made in section 4.5","metadata":{}},{"cell_type":"code","source":"X_train_transformed = preprocessor.fit_transform(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_feats_one_hot = preprocessor.transformers_[1][1]['onehotencoder'].get_feature_names(cat_feats)\n# print(cat_feats_one_hot)\n\nall_feats = list(num_feats)+list(cat_feats_one_hot)\n# print(all_feats)\n\ndict_for_renaming_cols = {}\nfor i in range(len(all_feats)):\n    dict_for_renaming_cols[i] = all_feats[i]\n# print(dict_for_renaming_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if scipy.sparse.issparse(X_train_transformed):\n    X_train_transformed_2 = pd.DataFrame.sparse.from_spmatrix(X_train_transformed)\nelse:\n    X_train_transformed_2 = pd.DataFrame(X_train_transformed)\nX_train_transformed_2.rename(columns=dict_for_renaming_cols,inplace=True)\n\nX_test_transformed = preprocessor.transform(X_test)\nif scipy.sparse.issparse(X_test_transformed):\n    X_test_transformed_2 = pd.DataFrame.sparse.from_spmatrix(X_test_transformed)\nelse:\n    X_test_transformed_2 = pd.DataFrame(X_test_transformed)\nX_test_transformed_2.rename(columns=dict_for_renaming_cols,inplace=True)\n\nX_transformed = preprocessor.transform(X)\nif scipy.sparse.issparse(X_transformed):\n    X_transformed_2 = pd.DataFrame.sparse.from_spmatrix(X_transformed)\nelse:\n    X_transformed_2 = pd.DataFrame(X_transformed)\nX_transformed_2.rename(columns=dict_for_renaming_cols,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_transformed_2.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_transformed_2.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.6.2 Label Encoding for categorical features","metadata":{}},{"cell_type":"code","source":"le = LabelEncoder()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make copies so that original aren't changed\nX_label_enc = X.copy()\nX_train_label_enc = X_train.copy()\nX_test_label_enc = X_test.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feat in cat_feats:\n    print('Feature:', feat)\n    X_label_enc[feat] = le.fit_transform(X_label_enc[feat])\n    X_train_label_enc[feat] = le.fit_transform(X_train_label_enc[feat])\n    X_test_label_enc[feat] = le.fit_transform(X_test_label_enc[feat])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_label_enc[cat_feats].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.7 Model Training","metadata":{}},{"cell_type":"markdown","source":"### 4.7.1 Choosing the transformation configuration","metadata":{}},{"cell_type":"code","source":"if transform_dataset == 'scaling_and_one_hot_encoding':\n    print('Method for data tranformation: scaling and one hot encoding')\n    X_train_for_model = X_train_transformed_2\n    X_test_for_model = X_test_transformed_2\n    X_for_model = X_transformed_2\n    X_test_for_shap = X_test_transformed_2\n    X_for_shap = X_transformed_2\nelif transform_dataset == 'label_encoding':\n    print('Method for data transformation: label encoding')\n    X_train_for_model = X_train_label_enc\n    X_test_for_model = X_test_label_enc\n    X_for_model = X_label_enc\n    X_test_for_shap = X_test_label_enc\n    X_for_shap = X_label_enc\nelif transform_dataset == 'no_transformation':\n    print('Method for data transformation: no transformation')\n    X_train_for_model = X_train\n    X_test_for_model = X_test \n    X_for_model = X\n    X_test_for_shap = X_test\n    X_for_shap = X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_feats","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.7.2 Converting the dataset into an lgb Dataset and setting the parameters for model training\nLightGBM model works on a specific datatype. The normal Pandas dataframe could be easily converted into that specific type by using lgb.Dataset() function","metadata":{}},{"cell_type":"code","source":"if transform_dataset == 'scaling_and_one_hot_encoding':\n    train_data=lgb.Dataset(X_train_for_model,label=y_train)\n    test_data=lgb.Dataset(X_test_for_model,label=y_test)\nelif transform_dataset == 'label_encoding':    \n    train_data=lgb.Dataset(X_train_for_model,label=y_train,categorical_feature=cat_feats)\n    test_data=lgb.Dataset(X_test_for_model,label=y_test,categorical_feature=cat_feats)\nelif transform_dataset == 'no_transformation':\n    train_data=lgb.Dataset(X_train_for_model,label=y_train)\n    test_data=lgb.Dataset(X_test_for_model,label=y_test)\nelse:\n    train_data=lgb.Dataset(X_train_for_model,label=y_train)\n    test_data=lgb.Dataset(X_test_for_model,label=y_test)\n    \nparams = {'metric': 'binary_logloss', \n          'boosting_type': 'gbdt', \n          'objective': 'binary',\n          'feature_fraction': 0.5,\n          'num_leaves': 15,\n          'max_depth': 10,\n          'n_estimators': 200,\n          'min_data_in_leaf': 200, \n          'min_child_weight': 0.1,\n          'reg_alpha': 2,\n          'reg_lambda': 5,\n          'subsample': 0.8,\n          'verbose': -1,\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.7.3 Training and Predicting using the LGBM classifier ","metadata":{}},{"cell_type":"code","source":"lgbm = lgb.train(params,\n                 train_data,\n                 2500,\n                 valid_sets=test_data,\n                 early_stopping_rounds= 100,\n                 verbose_eval= 20\n                 )\n\ny_prob = lgbm.predict(X_for_model)\ny_pred = y_prob.round(0)\n\nclf_roc_auc_score = roc_auc_score(y, y_prob)\nclf_accuracy_score = accuracy_score(y, y_pred)\n\nprint('Model overall ROC AUC score: {:.3f}'.format(clf_roc_auc_score))\nprint('Model overall accuracy: {:.3f}'.format(clf_accuracy_score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verify if the model has predicted a value between 1 and 0\nprint('Min value of prediction: {:.3f}'.format(y_pred.min()))\nprint('Max value of prediction: {:.3f}'.format(y_pred.max()))\nprint('Min value of probability: {:.3f}'.format(y_prob.min()))\nprint('Max value of probability: {:.3f}'.format(y_prob.max()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Evaluation of trained model on different classification metrics ","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Getting Recall, Precision and Specificity scores","metadata":{}},{"cell_type":"code","source":"# Getting all the accuracy metrics\ntn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n\nsensitivity = tp / (tp+fn) # Recall.\nspecificity = tn / (tn+fp)\nprecision = tp / (tp+fp)\n\nprint('Sensitivity/Recall: %.2f' % sensitivity)\nprint('Specificity: %.2f' % specificity)\nprint('Precision: %.2f' % precision)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Plotting the confusion matrix ","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(y, y_pred, normalize_str, figsize_w, figsize_h, filename):\n    \"\"\"\n    Plot the confusion matrix of a classifier.\n    \"\"\"\n    plt.figure(figsize=(figsize_w,figsize_h))\n    plt.title('Confusion matrix')\n    cm = confusion_matrix(y, y_pred, normalize=normalize_str)\n    df_cm = pd.DataFrame(cm, columns=np.unique(y), index = np.unique(y))\n    df_cm.index.name = 'Actual'\n    df_cm.columns.name = 'Predicted'\n    sns.set(font_scale=1.4)\n    sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})\n    plt.savefig(filename)\n    plt.show()\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(y=y, y_pred=y_pred, normalize_str='true', figsize_w=4, figsize_h=4, filename='./ConfusionMatrix.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 Plotting the ROC Curve","metadata":{}},{"cell_type":"code","source":"# True positive rate and false positive rate.\nfpr, tpr, _ = roc_curve(y, y_prob)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr, clf_name, figsize_w, figsize_h, filename):\n    \"\"\"\n    Plot the ROC curve of a classifier.\n    \"\"\"\n    plt.figure(figsize=(figsize_w,figsize_h))\n    sns.set(style=\"whitegrid\")\n    plt.plot([0, 1], [0, 1], 'k--', label='random')\n    plt.plot(fpr, tpr, label=clf_name)\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('ROC curve')\n    plt.legend(loc='best')\n    plt.savefig(filename)\n    plt.show()\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_roc_curve(fpr=fpr, tpr=tpr, clf_name='LightGBM', figsize_w=6, figsize_h=6, filename='./ROCCurve.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Saving the predictions in a new dataframe","metadata":{}},{"cell_type":"code","source":"# Saving results in a fresh dataframe\ndf_out = pd.DataFrame()\ndf_out['y_pred'] = y_pred\ndf_out['y_prob'] = y_prob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Plotting the recommendation probability","metadata":{}},{"cell_type":"code","source":"def plot_hist_sns(df,feat,bins,title,x_label,y_label,filename):\n    \"\"\"\n    Plot the histogram of a given feature.\n    \"\"\"\n    plt.figure(figsize=(6,6))\n    sns.distplot(df[feat],bins=bins,kde=False)\n    plt.title(title)\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.grid(False)\n    plt.savefig(filename)\n    plt.show()\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist_sns(df=df_out,\n             feat='y_prob',\n             bins=30,\n             title='Distribution of model prediction',\n             x_label='Predicted probability of being recommended',\n             y_label='Entries / bin',\n             filename='./HistModelPredictions.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Saving the predictions in an output file","metadata":{}},{"cell_type":"code","source":"df_out.to_csv(df_out_filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Thanks a lot for taking out time to read my work! Please feel free to leave any comments and recommendations for me to improve my work. If you liked the work, please feel free to press that \"little upward arrow\" button :) !!!**\n\n**Cheers!!**","metadata":{}}]}